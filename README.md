Все файлы, которые приведены в этом репозитории, служат двум целям:
1) Разработка модели классификации (обучение модели, различные эксперименты)
2) Эксплуатация модели классификации в реальном времени

# Начало работы с системой
Для корректного запуска всех программ **необходимо** создать conda окружение в соответствии с файлом environment.yml

Данная процедура выполняется один раз (при установке системы на объекте или при работе на рабочем компьютере) и нужна она для того, чтобы были доступны все внешние библиотеки, которые я использую для работы системы.
Для того, чтобы проверить, имеется ли необходимое виртуальное окружение на данный момент, нужно выполнить в консоли:

```bash
conda info --envs | grep ZB
```
- Если данная команда ничего не выдает, то виртаульное окружение не установлено

- Если выдает что-то начинающееся на ZB, то окружение уже установлено

**Инструкция по установке и активации виртуального окружения для Linux Ubuntu 22.04**
1) Установить miniconda (если miniconda не установлена, на linux ubuntu можно установить при помощи терминала в одну инструкцию):
   ```bash
   curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
   sh Miniconda3-latest-Linux-x86_64.sh
   ```
2) Далее, для создания виртуального окружения, нужно выполнить в терминале (в рабочей директории, где лежит файл environment.yaml):

   ```bash
   conda env create -f environment.yaml
   ```

3) После того, как виртуальное окружение создано, его можно активировать, слева от имени пользователя в терминале должна появиться надпись (ZB):
   ```bash
   conda activate ZB
   ```
---
**Обучение модели (выполняется специалистом, ответственным за математику и обучение моделей)**

>Для того, чтобы начать экспериментировать с обучением модели, тестировать различные гипотезы, сохранять новые версии моделей необходимо поставить виртуальное окружение (см. выше как это делать) и пойти в jupiter-notebook, например создать папку rnd, в которую скопировать все содержимое папки stable_version и внутри папки rnd начать экспериментировать с .ipynb файлом. Результатом работы в jupiter-notebook является обученная модель в формате .pkl

**Запуск классификатора на объекте**

Для того, чтобы запустить классификатор на объекте, нужно на компьютере на объекте:
* Поставить виртуальное окружение conda (инструкция выше)
* Перенести папку stable_version в папку ioes_python_detector на объекте
* Далее, в веб-морде Кирилла (в браузере ввести ```localhost:12175``` (p.s. 12175 - веб порт моего сервиса- классификатора)) указать путь до созданного виртуального окружения (это путь до бинарного файла python, на демостенде лежит здесь: /home/demostend/miniconda3/envs/ZB/bin/python3). Соответственно надо будет поменять "demostend" на что-то другое
* Скрипт starter.py и конфиг classifier_config.json перенести выше на одну директорию, так, чтобы они лежали ВМЕСТЕ С ФАЙЛАМИ ioes_python_detector и ioes_python_detector.service
* Нажать apply, затем подтвердить: нажать красную кнопку: Config not saved! Save!

> Если есть необходимость поменять какие-то настройки классификатора, например: нужно включить построение графиков в matplotlib в реальном времени,
>включить сохранение тревог для дальнейшего просмотра и разметки в GUI, снизить порог классификатора, повысить время охлаждения, снизить максимальное допустимую длительность сигнала и так далее (подробнее читать комментарии в mainloop.py), то необходимо:
> * поменять соответствующий параметр в classifier_config.json (смотреть ниже описание переменных)
> * нажать ctrl+s (сохранить файл)
> * сделать перезапуск сервиса через консоль: 
> ```systemctl --user restart ioes_python_detector```   
> ---
>**Описание переменных в classifier_config.json:**
>- model_path (str): строка-путь к модели машинного обучения, которая была обучена и сохранена в рамках экспериментов (путь до .pkl файла)
>- indent_time (int): время отступа от начала воздействия (в мс). Гаранитирует, что при появлении тревоги, начало воздействия пропущено не будет. По умолчанию 500 мс.
>- cooling_time (int): время охлаждения системы (в мс). Гарантирует полную запись как коротких, так и длинных воздействий. По умолчанию стоит 1000 мс.
>- max_time (int): максимальное время записываемого сигнала (в мс). При долгих воздействиях (время длительности больше max_time), классификация запускается принудительно для того сигнала что успел набраться.
>- threshold (int): порог превышения СКО детектора, измеряется в единицах СКО относительно шума прибора. СКО шума прибора пишется в первую секунду работы системы, поэтому при первом запуске лучше подождать одну-две секунды, чтобы детектор подобрал корректное СКО. По умолчанию стоит превышение порога в 3 раза.
>- plotting (bool): проводить ли построение графиков matplotlib (информация о сыром сигнале и распределение по вероятностям от классификатора). По умолчанию графики не строятся.
>- verbose (bool): передавать ли в консоль (и в дальнейшую систему отображения) информацию о работе классификатора? По умолчанию выводится в консоль, лучше этот параметр не трогать.
>- saving (bool): проводить ли сохранение тревог и соответствующих вероятностей от классификатора в директорию save_path? По умолчанию сохранения не происходит.
>- save_path (str): путь-строка до директории в которую производить сохранение тревог от классификатора. Этот параметр используется только при saving=True.
>- max_files_count (int): максимальное кол-во тревог, которое может быть сохранено в рамках одного часа. Сделано для защиты от переполнения директории в случаее поломки и очень частых срабатываний детектора, осуществляет сохранение в формате кольцевого буфера (новые тревоги вытесняют самые старые). По умолчанию стоит максимально сохраняется 250 тревог в рамках часа.
>---

# Описание файлов в директории 

Формат хранения скриптов в директории: в одной папке лежит весь проект: все необходимые скрипты
как для запуска python detector в режиме реального времени, так и для обучения модели,
различных экспериментов с данными (в jupyter-notebook)

1) stable_version - готовая рабочая версия классификатора, протестированная на демостенде (интеграция с outpost)
2) mp_version - версия проекта в котором используется бэкенд python для получения данных (без интеграции с outpost), это пока не доработанная версия. По сути в дальнейшем придется дорабатывать именно эту версию, так как планируется переход на python бэкенд. Главное отличие этого проекта от stable_version состоит в том, что в нем реализуется получение данных в другом формате. В stable_version получение данных идет через stdin, отправка в stdout, в версии mp_version прием и отправка данных идет через unix-сокеты и python. 
3) notebooks - здесь хранятся различные экспериментальные jupyter-notebooks для исследовании, экспериментов, обучения моделей. Например есть notebook_test_nn.ipynb в котором описаны базовые Dataset и Dataloader для pytorch получения данных в интерфейсе pytorch, в этом ноутбуке можно пробовать обучать разные нейросети через pytorch.  
4) models - сохраненные обученные модели. pipeline_with_kashira.pkl - последняя версия обученного sklearn-pipeline, эта модель была обучена на данных с разных объектов (Демостенд, Цесис, Кашира, Норильск)
5) content - хранилище со вспомогательными изображениями, видео для презентаций работы разметчика данных через GUI

# Описание процесса классификации

Основные цели разработанной системы классификации:

1) Постоянное получение данных с интерферометра
2) Детектирование факта воздействия на забор
3) Выдача метки классификации

Ниже приведена визуальная схема того как система работает на данный момент

![Модульная схема работы системы](content/scheme.png)

Система (на данный момент за исключением data receiver и data sender) представляет из себя последовательно идущие модули (которые могут быть заменены при желании). Модули оформлены в виде классов и лежат в отдельных .py скриптах. Для более подробного ознакомления смотреть код (необходимые комментарии оставлены)

## Data receiver
Для получения данных с интерферометра на данный момент используется чтение из буффера ввода. В буффер данные попадают через backend Кирилла. На данный момент data receiver не оформлен в виде отдельного класса, потому что для получения данных достаточно в бесконечном цикле читать данные из буфера (при запущенном сервисе Кирилла), логика простая. Данные будут приходить по 1000 значений в секунду.
Запуск сервиса Кирилла:
```bash
# Перезапуск сервиса Кирилла, 
# при запущенном сервисе в буффер поступают данные с интерферометра по 1000 значений в секунду.
systemctl --user restart ioes_python_detector
```
## Detector
В первую секунду работы системы детектор получает 1000 отсчетов по которым считает СКО. Посчитанное значение выступает в качестве опорного значения шума устройства. Значение threshold означает: во сколько раз необходимо превысить шум прибора чтобы тревога поднялась (detect выдал True)? (например threshold = 3 -> в три раза)

## Cropper
Логика в виде кода описана в cropper.py

Cropper работает в связке с детектором. В одну секунду приходит 1000 значений (один фрейм). Детектор на этот фрейм выдает True/False. В случае если впервые зафиксирована тревога (детектор вернул True), то отсчитывается отступ от начала воздействия, начинается запись сигнала пока продолжается тревога. Запись прекращается в двух случаях: 
1) превышено максимальное время записи устанавливаемое пользователем (например 10 секунд. В этом случае система не будет дожидаться окончания воздействия (например длинного перелаза или долгого ветра), а будет выдавать метку классификации через 10 секунд.)
2) тревога не поднимается в течении времени охлаждения (например в случае короткого удара только один первый фрейм вызовет True у детектора, последующие фреймы поднимут False, поэтому запись закончится по времени охлаждения)

## Preprocessor
Preprocessor получает от Cropper обрезанный сигнал и выдает данные в формате, необходимом для модели. В нынешней конфигурации классификатора одной из составляющих является tsfresh extract_features для перевода временных рядов переменной длительности в табличное представление (путем вычисления различных статистических признаков из сигнала). Так как extract_features требует [определенный формат данных на входе](https://tsfresh.readthedocs.io/en/latest/text/data_formats.html), то Preprocessor переводит данные, полученные Cropper-ом в формат требуемый extract_features (я назвал этот формат longDataFrame).

В силу того, что:
1)  Сырой сигнал представляет собой колебания вокруг постоянного уровня (который может находится на любом уровне) разной амплитуды (в зависимости от чувствительности интерферометра)
2) Отклонения от постоянного уровня могут быть как биполярными (в обе стороны от постоянного уровня), так и униполярными (только в одну сторону от постоянного уровня)
3) Статистические признаки, извлекаемые tsfresh.extract_features напрямую из сырого, неотфильтрованного сигнала, получаются довольно неустойчивыми (информацию о воздействии несет скорее огибающая сигнала а не сам сигнал от вибраций).

Использование только сырого сигнала не привело к хорошим показателям качества классификатора. Поэтому извлекать признаки не только из сырого сигнала, а извлекать определенные признаки (описанные в preprocessing.py) из:

* сигнала, отфильтрованного скользящим средним (несет информацию о низкочастотной составляющей).
* сигнала, отфильтрованного скользящим СКО (несет информацию о высокочастотной составляющей).
* спектра Фурье, сгруппированного по частотам (при анализе сигналов было выявлено, что больше информации несут низкочастотные участки спектра, поэтому поверх фурье-спектра используется усредняющее окно с меняющимся размером: при малых частотах это окно мало, потом экспоненциально увеличивается).

  Отфильтрованные сигналы (скользящее среднее, скользящее СКО) лежат в одном longDataFrame.
  Фурье-спектр сигнала лежит в другом longDataFrame 

## Classifier
Классификатор представлен в виде [sklearn-pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), также рекомендуется изучить способ интеграции tsfresh и sklearn-pipeline [ссылка к изучению](https://tsfresh.readthedocs.io/en/latest/text/sklearn_transformers.html). Вообще указание структуры классификатора, его обучение и сохранение происходит внутри jupiter-notebook. При желании можно заменить классификатор на свой (в этом случае, если остальные части системы оставлять неизменными, нужно будет отредактировать класс Classifier в classifier.py: переопределить нужным образом инициализацию классификатора, метод predict)

### Описание нынешней версии классификатора

Ниже приведена схема прохода данных через классификатор

![Схема классификатора](content/zb_classifier.png)


Данные, после прохождения через Preprocessing, представляют собой два dataframe: longDataFrame (с сигналами во временной области), longFreqDataFrame (с сигналом в частотной области). Для каждого датафрейма происходит извлечение своих признаков (список извлекаемых признаков описан в Preprocessing.py) Затем происходит конкатенация полученных признаков в одну таблицу: это и есть табличное представление сигнала. После того как сигнал преобразован в табличное представление, можно использовать алгоритмы классического машинного обучения для решения задачи многоклассовой классификации. Для данной задачи был выбран класификатор RandomForest (Случайный лес) 

Обоснование выбора модели:
Boosting или Bagging? (Два основных претендента на высокое качество работы для данных этой природы)
1) В условиях зашумленных признаков (сильный удар может быть похож на перелаз, перепил. Перепил по характеристикам может быть похож на перелаз) случайный лес показывает хорошее качество и работает лучше чем градиентный бустинг.
2) В режиме реального времени требуется быстрое предсказание (Случайный лес может быть распараллелен, бустинг - последовательный алгоритм, распараллелен быть не может)
3) Интерпретация: Отдельные деревья в случайном лесе легче интерпретируются, для бустинга процесс интерпретации сложнее.
Вообще интересное направление - использование нейросетей, возможно при помощи них удасться сделать качество лучше, в notebooks есть начало экспериментов на эту тему, с использованием pytorch. Смотреть notebooks/notebook_test_nn.ipynb
## Data Sender
Выход классификатора должен быть согласован с Sender.
На данный момент передача метки классификации происходит в стандартный поток вывода (в консоль), оттуда классификация идет дальше в систему отображения outpost zb.
Для просмотра вывода классификатора используется просмотр журнала сервиса:
```bash
journalctl --user -f -u ioes_python_detector
```
## Mainloop
Скрипт, в котором определен класс, где собирается все вместе: detector, cropper, classifier, saver, и при помощи этих
"строительных блоков" строится основная логика (по сути метод start который сам по себе маленький)

## starter.py
Этот python скрипт является программой, котораязапускающей классификатор в режиме реального времени,
в нем запускается Mainloop, для конфигурации классификатора используется classifier_config.json внутри которого
записаны переменные отвечающие за работу классификатора.



# Сохранение и просмотр тревог.

Во время работы классификатора имеется возможность включить авто сохранение тревог. При сохранении тревоги записывается:
 * сигнал, который привел к тревоге
 * дата, время тревоги
 * json-строка с вероятностями по классам.

Сохранение тревог в таком формате преследует две цели:
   1) Автоматический набор данных для дальнейшего обучения модели
   2) Проверка корректности работы классификатора

Объект отвечающий за сохранение тревог, представляет собой класс Saver внутри скрипта scripts/saver.py

Ниже приведена файловая структура сохранения тревог:

## Файловая структура при сохранении тревоги (пример)

- ./data/  
  - /610/
    - /2025_05_13/  
      - /05h
        - 610_2025_05_13_05_00_00_000.hdf5
      - /06h
        - 610_2025_05_13_06_00_00_000.hdf5
      - /13h
        - 610_2025_05_13_13_00_00_000.hdf5 
      - /23h 
        - 610_2025_05_13_23_00_00_000.hdf5  
    - /2025_05_15/
      - /08h
        - 610_2025_05_15_08_00_00_000.hdf5   
  - /775/
    - /2025_05_13/ 
      - /14h
        - 775_2025_05_13_14_00_00_000.hdf5
    ...

  - marker.txt


Такая вложенная файловая структура для хранения тревог позволяет сохранять в отдельные файлы тревоги отдельных зон, дней, часов и при повреждении какого-то файла будет утеряна информация за один час.

Название hdf5 файла содержит всю информацию о зоне, дате, часе сработки (эта избыточность информации в названии файла обуcловлена историческими требованиями отдела ОРПО). hdf5 файл содержит в себе датасеты (один датасет - одна тревога) у каждого датасета есть аттрибуты: "date_time" (дата и время тревоги), "probabilities" (строка-json с класами и соответствующими вероятностями)

---

## Графический интерфейс для просмотра тревог

>[!warning] 
>1) Нельзя использовать GUI для просмотра тревог, в "работающей" директории (то есть когда классификатор записывает в просматриваемую директорию новые тревоги). Это может привести к аварийному вылету приложения. 
>
>2) Вылеты приложения скорее всего означают нарушение файловой структруры при сохранении или пустое содержимое hdf5 файлов. Поэтому вручную лучше не изменять создаваемые вложенные директории. 
p.s. Данный интерфейс создан для удобства разметки и просмотра тревог и не проходил полную отладку на всевозможные баги, при аварийных завершениях рекомендуется перезапустить интерфейс

Для удобного просмотра сработок алгоритма, назначения тревогам меток можно использовать скрипт GUI_viewer.py (работает только для просмотра тревог, хранящихся во вложенной структуре, описанной выше (класс Saver обеспечивает сохранение в таком формате)). 

```bash
# активация виртуального окружения
conda activate ZB
# запуск скрипта GUI_viewer.py
python3 stable_version/GUI_viewer.py
```

Ниже представлен скриншот интерфейса для просмотра/разметки тревог:
![GUI для анализа тревог](content/gui_pic.png)

После запуска приложения нужно:
1) Нажать кнопку выбрать директорию (выделена зеленым цветом на панели справа)
2) В появившемся меню выбрать путь до папки в которой лежит хранилище со вложенной структурой(подсказка: там лежат папки с зонами)
3) Нажать на зеленую кнопку "выбрать зону"справа внизу, выбрать в появившемся меню номер нужной зоны
4) Далее можно перемещаться по тревогам для просмотра. Для этого можно использовать: календарь для перехода на конкретную дату, кнопки "Перейти к следующей тревоге", "Перейти к предыдущей тревоге" для переключения между ближайшими по времени тревогами. При переходе на новое воздействие отображается: сигнал который привел к срабатыванию алгоритма (после cropper), в соседнем окне справа появляются вероятности классов которые выдал классификатор при срабатывании.
5) Если нужно перейти в режим разметки, то нужно нажать на кнопку "Изменить список тревог для разметки" (нижняя большая кнопка).
6) В появившемся меню появится список названий классов для разметки (с новой строки новое название). По умолчанию уже установлен стандартный набор: hit, hit_series, saw, perelaz, unknown (одиночный удар, серия ударов, перепил, перелаз, неизвестное воздействие). Если нужно добавить свои классы, то нужно написать их в таком же формате
7) После выбора меток для разметки появится опция выбора истинной метки для сигнала. При выборе воздействия у соответствующего hdf5 файла меняется (или создается если отсутствует) аттрибут label на тот что был выбран.

Демонстрация работы в GUI (видео):

[Демонстрация работы интерфейса (MP4)](content/demoGUI.mp4)
[Разметка данных, набранных в Кашире](content/razmetka_kashira.mp4)
